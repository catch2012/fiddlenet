


@article{RefWorks:32,
	author={A. P. Bradley},
	year={1997},
	title={{The use of the area under the ROC curve in the evaluation of machine learning algorithms}},
	journal={Pattern recognition.},
	volume={30},
	number={7},
	pages={1145},
	isbn={0031-3203},
	language={english}
}

@article{RefWorks:34,
	author={Chris Drummond and Nathalie Japkowicz},
	year={2010},
	title={Warning: statistical benchmarking is addictive. {K}icking the habit in machine learning},
	journal={Journal of Experimental {\&} Theoretical Artificial Intelligence},
	volume={22},
	number={1},
	pages={67-80},
	abstract={Algorithm performance evaluation is so entrenched in the machine learning community that one could call it an addiction. Like most addictions, it is harmful and very difficult to give up. It is harmful because it has serious limitations. Yet, we have great faith in practicing it in a ritualistic manner: we follow a fixed set of rules telling us the measure, the data sets and the statistical test to use. When we read a paper, even as reviewers, we are not sufficiently critical of results that follow these rules. Here, we will debate what are the limitations and how to best address them. This article may not cure the addiction but hopefully it will be a good first step along that road.},
	isbn={0952-813X},
	language={english}
}

@inproceedings{RefWorks:36,
	author={Marina Sokolova},
	year={2006},
	month={December},
	title={Assessing invariance properties of evaluation  measures},
	booktitle={Proceedings of the Workshop on Testing of Deployable Learning and Decision Systems, the 19th Neural Information Processing Systems Conference (NIPS 2006)},
	location={Vancouver, B.C., Canada},
	abstract={This study emphasizes the importance of using appropriate measures in particular text classification settings. We focus on methods that evaluate how well a classifier performs. The effect of transformations on the confusion  matrix are considered for eleven well-known and recently introduced classification measures. We analyze the measureâ€™s ability to retain its value under changes in a confusion matrix. We discuss benefits from the use of the invariant and non-invariant measures with respect to characteristics of data classes.},
	language={english}
}

@inproceedings{RefWorks:37,
	author={M. Sokolova and N. Japkowicz and S. Szpakowicz},
	year={2006},
	month={December 4-8},
	title={{Beyond Accuracy, F-Score and ROC: A Family of Discriminant Measures for Performance Evaluation}},
	booktitle={AI 2006: Advances in Artificial Intelligence: 19th Australian Joint Conference on Artificial Intelligence},
	location={Hobart, Australia},
	language={english}
}

@article{RefWorks:33,
	author={M. Sokolova and G. Lapalme},
	year={2009},
	title={A systematic analysis of performance measures for classification tasks},
	journal={Information Processing and Management},
	volume={45},
	number={4},
	pages={427-437},
	abstract={This paper presents a systematic analysis of twenty four performance measures used in the complete spectrum of Machine Learning classification tasks, i.e., binary, multi-class, multi-labelled, and hierarchical. For each classification task, the study relates a set of changes in a confusion matrix to specific characteristics of data. Then the analysis concentrates on the type of changes to a confusion matrix that do not change a measure, therefore, preserve a classifier's evaluation (measure invariance). The result is the measure invariance taxonomy with respect to all relevant label distribution changes in a classification problem. This formal analysis is supported by examples of applications where invariance properties of measures lead to a more reliable evaluation of classifiers. Text classification supplements the discussion with several case studies.},
	isbn={0306-4573},
	language={english}
}

