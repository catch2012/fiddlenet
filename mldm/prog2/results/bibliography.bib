@book{Mitchell1997,
	author={Tom M. Mitchell},
	year={1997},
	title={Machine Learning},
	publisher={McGraw-Hill},
	address={New York},
	isbn={0070428077 9780070428072 0071154671 9780071154673},
	language={English}
}

@article{RefWorks:44,
  author = {Satosi Watanabe},
  year = {1960},
  title = {{Information Theoretical Analysis of Multivariate Correlation}},
  journal = {IBM Journal of Research and Development},
  volume = {4},
  number = {1},
  pages = {66-82},
  abstract = {A set λ of stochastic variables, y1 ,y2, …, yn, is grouped into subsets, µ1, µ2, ..., µk. The correlation existing in λ with respect to the µ's is adequately expressed by an equation where S(ν) is the entropy function defined with reference to the variables y in subset ν. For a given λ, C becomes maximum when each µi consists of only one variable, (n = k). The value C is then called the total correlation in λ, Ctot(λ). The present paper gives various theorems, according to which Ctot(λ) can be decomposed in terms of the partial correlations existing in subsets of λ, and of quantities derivable therefrom. The information-theoretical meaning of each decomposition is carefully explained. As illustrations, two problems are discussed at the end of the paper: (1) redundancy in geometrical figures in pattern recognition, and (2) randomization effect of shuffling cards marked “zero” or “one.”},
  isbn = {0018-8646}
}

@misc{Frank+Asuncion:2010,
author = "A. Frank and A. Asuncion",
year = "2010",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" } 

@misc{wiki:total_correlation,
   author = "Wikipedia",
   title = "{W}ikipedia{,} The Free Encyclopedia",
   year = "2010",
   url = "\url{http://en.wikipedia.org/wiki/Total\_correlation}",
   note = "[Online; accessed 10-Nov-2010]"
 }
